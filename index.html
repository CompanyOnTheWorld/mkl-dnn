<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Mkl-dnn by CompanyOnTheWorld</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/github-dark.css">
    <script src="javascripts/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1>Mkl-dnn</h1>
        <p>Intel(R) Math Kernel Library for Deep Neural Networks (Intel(R) MKL-DNN)</p>
        <p class="view"><a href="https://github.com/CompanyOnTheWorld/mkl-dnn">View the Project on GitHub <small>CompanyOnTheWorld/mkl-dnn</small></a></p>
        <ul>
          <li><a href="https://github.com/CompanyOnTheWorld/mkl-dnn/zipball/master">Download <strong>ZIP File</strong></a></li>
          <li><a href="https://github.com/CompanyOnTheWorld/mkl-dnn/tarball/master">Download <strong>TAR Ball</strong></a></li>
          <li><a href="https://github.com/CompanyOnTheWorld/mkl-dnn">View On <strong>GitHub</strong></a></li>
        </ul>
      </header>
      <section>
        <h1>
<a id="intelr-math-kernel-library-for-deep-neural-networks-intelr-mkl-dnn" class="anchor" href="#intelr-math-kernel-library-for-deep-neural-networks-intelr-mkl-dnn" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Intel(R) Math Kernel Library for Deep Neural Networks (Intel(R) MKL-DNN)</h1>

<p><a href="LICENSE"><img src="https://img.shields.io/badge/license-Apache_2.0-green.svg" alt="Apache License Version 2.0"></a>
<img src="https://img.shields.io/badge/version-technical_preview-orange.svg" alt="Technical Preview"></p>

<p>Intel(R) Math Kernel Library for Deep Neural Networks (Intel(R) MKL-DNN) is an
open source performance library for Deep Learning (DL) applications intended
for acceleration of DL frameworks on Intel(R) architecture. Intel(R) MKL-DNN
includes highly vectorized and threaded building blocks for implementation of
convolutional neural networks (CNN) with C and C++ interfaces. We created this
project to help DL community innovate on Intel(R) processors.</p>

<p>Intel MKL-DNN functionality shares implementation with <a href="https://software.intel.com/en-us/intel-mkl">Intel(R) Math Kernel
Library (Intel(R) MKL)</a>, but is not
API compatible with Intel MKL 2017. We will be looking into ways to converge
API in future releases of Intel MKL.</p>

<p>This release is a technical preview with functionality limited to AlexNet and
VGG topologies forward path. While this library is in
technical preview phase, its API may change without considerations of backward
compatibility.</p>

<h2>
<a id="license" class="anchor" href="#license" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>License</h2>

<p>Intel MKL-DNN is licensed under
<a href="http://www.apache.org/licenses/LICENSE-2.0">Apache License Version 2.0</a>.</p>

<h2>
<a id="documentation" class="anchor" href="#documentation" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Documentation</h2>

<p>You can find the latest Intel MKL-DNN documentation at <a href="http://01org.github.io/mkl-dnn/">GitHub pages</a>.</p>

<h2>
<a id="support" class="anchor" href="#support" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Support</h2>

<p>Please report issues and suggestions via
<a href="https://github.com/01org/mkl-dnn/issues">GitHub issues</a> or start a topic on
<a href="https://software.intel.com/en-us/forums/intel-math-kernel-library">Intel MKL forum</a>.</p>

<h2>
<a id="how-to-contribute" class="anchor" href="#how-to-contribute" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>How to Contribute</h2>

<p>We welcome community contributions to Intel MKL-DNN. If you have an idea how to improve the product:</p>

<ul>
<li><p>Let us know about your proposal via
<a href="https://github.com/01org/mkl-dnn/issues">GitHub issues</a>.</p></li>
<li><p>Make sure you can build the product and run all the examples with your patch</p></li>
<li><p>In the case of a larger feature, create a test</p></li>
<li><p>Submit a <a href="https://github.com/01org/mkl-dnn/pulls">pull request</a></p></li>
</ul>

<p>We will review your contribution and, if any additional fixes or modifications
are necessary, may give some feedback to guide you. When accepted, your pull
request will be merged into our internal and GitHub repositories.</p>

<h2>
<a id="system-requirements" class="anchor" href="#system-requirements" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>System Requirements</h2>

<p>Intel MKL-DNN supports Intel(R) 64 architecture processors and is optimized for</p>

<ul>
<li>Intel(R) Xeon(R) processor E5-xxxx v3 (codename Haswell)</li>
<li>Intel(R) Xeon(R) processor E5-xxxx v4 (codename Broadwell)</li>
</ul>

<p>Processors without Intel(R) Advanced Vector Extensions 2 (Intel(R) AVX2) are not
supported in this release.</p>

<p>Software dependencies:</p>

<ul>
<li>
<a href="https://cmake.org/download/">Cmake</a> 2.8.0 or later</li>
<li>
<a href="http://www.stack.nl/%7Edimitri/doxygen/download.html#srcbin">Doxygen</a> 1.8.5 or later</li>
<li>C++ compiler with C++11 standard support</li>
</ul>

<p>The software was validated on RedHat* Enterprise Linux 7 with</p>

<ul>
<li>GNU* Compiler Collection 4.8</li>
<li>GNU* Compiler Collection 6.1</li>
<li>Clang* 3.8.0</li>
<li>
<a href="https://software.intel.com/en-us/intel-parallel-studio-xe">Intel(R) C/C++ Compiler</a>
16.0 or later</li>
</ul>

<p>The implementation relies on OpenMP* SIMD extensions, and we recommend using
Intel(R) compiler for the best performance results.</p>

<h2>
<a id="installation" class="anchor" href="#installation" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Installation</h2>

<p>Download <a href="https://github.com/01org/mkl-dnn/archive/master.zip">Intel MKL-DNN source code</a>
or clone the repository to your system</p>

<pre><code>    git clone https://github.com/01org/mkl-dnn.git
</code></pre>

<p>Before the installation, make sure that all the dependencies are available and
have correct versions. Intel MKL-DNN uses optimized matrix-matrix
multiplication (GEMM) routine from Intel MKL. Dynamic library with this
functionality is included with the Intel MKL-DNN release. Before building the
project download the library using provided script</p>

<pre><code>    cd scripts &amp;&amp; ./prepare_mkl.sh &amp;&amp; cd ..
</code></pre>

<p>or download manually and unpack to <code>external</code> directory in the repository root.</p>

<p>Intel MKL-DNN uses CMake-based build system</p>

<pre><code>    mkdir -p build &amp;&amp; cd build &amp;&amp; cmake .. &amp;&amp; make
</code></pre>

<p>Intel MKL-DNN includes unit tests implemented using the googletest
framework. To validate the build, run:</p>

<pre><code>    make test
</code></pre>

<p>Documentation is provided inline and can be generated in HTML format with
Doxygen:</p>

<pre><code>    make doc
</code></pre>

<p>Documentation will be created in <code>build/reference/html</code> folder.</p>

<p>Finally,</p>

<pre><code>    make install
</code></pre>

<p>will put header files, libraries and documentation to <code>/usr/local</code>. To change
installation path use the option <code>-DCMAKE_INSTALL_PREFIX=&lt;prefix&gt;</code> when invoking
CMake.</p>
      </section>
    </div>
    <footer>
      <p>Project maintained by <a href="https://github.com/CompanyOnTheWorld">CompanyOnTheWorld</a></p>
      <p>Hosted on GitHub Pages &mdash; Theme by <a href="https://github.com/orderedlist">orderedlist</a></p>
    </footer>
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->
    
  </body>
</html>
